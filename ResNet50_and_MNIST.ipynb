{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ResNet_and_Aug.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uivya3ICHyqB"
      },
      "source": [
        "In this notebook I will train Residual Network 50 with MNIST. Let's get started. \r\n",
        "First of all import all necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXMIYpZa6O8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "223a0958-c243-42df-dc9e-1c937a5c4ec5"
      },
      "source": [
        "import numpy as np\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.data import Dataset\r\n",
        "import tensorflow.keras as keras\r\n",
        "from keras import layers\r\n",
        "from keras.losses import BinaryCrossentropy\r\n",
        "from keras.metrics import BinaryAccuracy,Accuracy\r\n",
        "from keras.layers import Reshape,Input,Add,Lambda, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\r\n",
        "from keras.optimizers import SGD,RMSprop,Adam\r\n",
        "from keras.layers import Layer,UpSampling2D,Conv2DTranspose,AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\r\n",
        "from keras.models import Model,Sequential\r\n",
        "from keras.callbacks import Callback,ModelCheckpoint,EarlyStopping,LearningRateScheduler\r\n",
        "from keras.preprocessing import image\r\n",
        "from keras.utils import layer_utils,to_categorical\r\n",
        "from keras.utils.data_utils import get_file\r\n",
        "from keras.applications.imagenet_utils import preprocess_input\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "import pydot\r\n",
        "from IPython.display import SVG\r\n",
        "from keras.utils.vis_utils import model_to_dot\r\n",
        "from keras.utils import plot_model\r\n",
        "import keras.backend as K\r\n",
        "K.set_image_data_format('channels_last')\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from matplotlib.pyplot import imshow\r\n",
        "from keras.datasets import cifar100, mnist\r\n",
        "%matplotlib inline\r\n",
        "tf.keras.backend.set_floatx('float32')\r\n",
        "%load_ext tensorboard\r\n",
        "EPOCHS=50\r\n",
        "BATCHSIZE=32\r\n",
        "NCOLS=5\r\n",
        "NROWS=2\r\n",
        "NEXAM=10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D91qQsLRISRF"
      },
      "source": [
        "Load MNIST database, Expand Dimension of 3rd axis(batch_size,28,28,1). For well-training resizing image by 64x64. Create validation, test sets. Startup Image Generator, flow it. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xgUL2-J8_GL",
        "outputId": "8d255621-7c0e-48e7-ac8f-4b7c4c3e2045"
      },
      "source": [
        "(tX,tY),(teX,teY) = mnist.load_data()\r\n",
        "tX,teX=np.expand_dims(tX,axis=3),np.expand_dims(teX,axis=3)\r\n",
        "resizer = Lambda(lambda x: tf.image.resize(x,(64,64)))\r\n",
        "tX,teX = resizer(tX),resizer(teX)\r\n",
        "valX,valY = teX[:4000],teY[:4000]\r\n",
        "print(valY.shape)\r\n",
        "train_data = ImageDataGenerator(rescale=1./255,\r\n",
        "                                horizontal_flip=True,\r\n",
        "                                vertical_flip=True,\r\n",
        "                                rotation_range=40,\r\n",
        "                                width_shift_range=0.2,\r\n",
        "                                height_shift_range=0.2,\r\n",
        "                                shear_range=0.2,\r\n",
        "                                zoom_range=0.2)\r\n",
        "val_data = ImageDataGenerator(rescale=1./255)\r\n",
        "train_data.fit(tX)\r\n",
        "val_data.fit(valX)\r\n",
        "train_gen = train_data.flow(tX,tY,batch_size=BATCHSIZE,shuffle=True)\r\n",
        "val_gen = val_data.flow(valX,valY,batch_size=BATCHSIZE-20,shuffle=True)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(4000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXBtOrLPIpwC"
      },
      "source": [
        "Create Residual and Residual Convolutional layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5BkpEmMFnHt"
      },
      "source": [
        "def identity(X,f,F):\r\n",
        "  F1,F2,F3=F\r\n",
        "  Xs = X\r\n",
        "  X = Conv2D(filters=F1,kernel_size=(1,1),kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.001))(X)\r\n",
        "  X = BatchNormalization(axis=3)(X)\r\n",
        "  X = Activation('relu')(X)\r\n",
        "\r\n",
        "  X = Conv2D(filters=F2,kernel_size=(f,f),padding='same',kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.001))(X)\r\n",
        "  X = BatchNormalization(axis=3)(X)\r\n",
        "  X = Activation('relu')(X)\r\n",
        "\r\n",
        "  X = Conv2D(filters=F3,kernel_size=(1,1),kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.001))(X)\r\n",
        "  X = BatchNormalization(axis=3)(X)\r\n",
        "  X = Add()([X,Xs])\r\n",
        "  X = Activation('relu')(X)\r\n",
        "  return X\r\n",
        "def conv_block(X,f,F,s=2):\r\n",
        "  F1,F2,F3=F\r\n",
        "  Xs = X\r\n",
        "  X = Conv2D(filters=F1,kernel_size=(1,1),strides=(s,s),kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.001))(X)\r\n",
        "  X = BatchNormalization(axis=3)(X)\r\n",
        "  X = Activation('relu')(X)\r\n",
        "\r\n",
        "  X = Conv2D(filters=F2,kernel_size=(f,f),padding='same',kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.001))(X)\r\n",
        "  X = BatchNormalization(axis=3)(X)\r\n",
        "  X = Activation('relu')(X)\r\n",
        "\r\n",
        "  X = Conv2D(filters=F3,kernel_size=(1,1),kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.001))(X)\r\n",
        "  X = BatchNormalization(axis=3)(X)\r\n",
        "  \r\n",
        "  Xs = Conv2D(filters=F3,kernel_size=(1,1),strides=(s,s),kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.001))(Xs)\r\n",
        "  Xs = BatchNormalization(axis=3)(Xs)\r\n",
        "  X = Add()([X,Xs])\r\n",
        "  X = Activation('relu')(X)\r\n",
        "  \r\n",
        "  return X\r\n",
        "\r\n",
        "def conv_block(X,f,F,s=2):\r\n",
        "  F1,F2,F3=F\r\n",
        "  Xs = X\r\n",
        "  X = Conv2D(filters=F1,kernel_size=(1,1),strides=(s,s),kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.001))(X)\r\n",
        "  X = BatchNormalization(axis=3)(X)\r\n",
        "  X = Activation('relu')(X)\r\n",
        "\r\n",
        "  X = Conv2D(filters=F2,kernel_size=(f,f),padding='same',kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.001))(X)\r\n",
        "  X = BatchNormalization(axis=3)(X)\r\n",
        "  X = Activation('relu')(X)\r\n",
        "\r\n",
        "  X = Conv2D(filters=F3,kernel_size=(1,1),kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.001))(X)\r\n",
        "  X = BatchNormalization(axis=3)(X)\r\n",
        "  \r\n",
        "  Xs = Conv2D(filters=F3,kernel_size=(1,1),strides=(s,s),kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.001))(Xs)\r\n",
        "  Xs = BatchNormalization(axis=3)(Xs)\r\n",
        "  X = Add()([X,Xs])\r\n",
        "  X = Activation('relu')(X)\r\n",
        "  \r\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku3vY6Zfgt4w"
      },
      "source": [
        "class ResidualConv(Layer):\r\n",
        "  def __init__(self, f,F,s,**kwargs):\r\n",
        "        super(ResidualConv, self).__init__(**kwargs)\r\n",
        "        self.F,self.f,self.s=F,f,s\r\n",
        "  def build(self,inputs):\r\n",
        "        F1,F2,F3=self.F\r\n",
        "        self.conv1=Conv2D(filters=F1,kernel_size=(1,1),strides=(self.s,self.s))\r\n",
        "        self.bn1=BatchNormalization(axis=3)\r\n",
        "        self.conv2=Conv2D(filters=F2,kernel_size=(self.f,self.f),padding='same')\r\n",
        "        self.bn2=BatchNormalization(axis=3)\r\n",
        "        self.conv3=Conv2D(filters=F3,kernel_size=(1,1))\r\n",
        "        self.bn3=BatchNormalization(axis=3)\r\n",
        "        self.conv4=Conv2D(filters=F3,kernel_size=(1,1),strides=(self.s,self.s))\r\n",
        "        self.bn4=BatchNormalization(axis=3)\r\n",
        "\r\n",
        "  def call(self, x):\r\n",
        "     xs = x\r\n",
        "     x = self.conv1(x)\r\n",
        "     x = self.bn1(x)\r\n",
        "     x = tf.nn.relu(x)\r\n",
        "    \r\n",
        "     x = self.conv2(x)\r\n",
        "     x = self.bn2(x)\r\n",
        "     x = tf.nn.relu(x)\r\n",
        "\r\n",
        "     x = self.conv3(x)\r\n",
        "     x = self.bn3(x)\r\n",
        "     xs = self.conv4(xs)\r\n",
        "     xs = self.bn4(xs)\r\n",
        "     x+=xs\r\n",
        "     \r\n",
        "     x=tf.nn.relu(x)\r\n",
        "     return x\r\n",
        "class Residual(Layer):\r\n",
        "  def __init__(self, f,F,**kwargs):\r\n",
        "        super(Residual, self).__init__(**kwargs)\r\n",
        "        self.F,self.f=F,f\r\n",
        "  def build(self,inputs):\r\n",
        "        F1,F2,F3=self.F\r\n",
        "        self.conv1=Conv2D(filters=F1,kernel_size=(1,1))\r\n",
        "        self.bn1=BatchNormalization(axis=3)\r\n",
        "        self.conv2=Conv2D(filters=F2,kernel_size=(self.f,self.f),padding='same')\r\n",
        "        self.bn2=BatchNormalization(axis=3)\r\n",
        "        self.conv3=Conv2D(filters=F3,kernel_size=(1,1))\r\n",
        "        self.bn3=BatchNormalization(axis=3)\r\n",
        "  def call(self, x):\r\n",
        "     xs = x\r\n",
        "     x = self.conv1(x)\r\n",
        "     x = self.bn1(x)\r\n",
        "     x = tf.nn.relu(x)\r\n",
        "     x = self.conv2(x)\r\n",
        "     x = self.bn2(x)\r\n",
        "     x = tf.nn.relu(x)\r\n",
        "     x = self.conv3(x)\r\n",
        "     x = self.bn3(x)\r\n",
        "     x += xs\r\n",
        "     x = tf.nn.relu(x)\r\n",
        "     return x\r\n",
        "\r\n",
        "class ZP(Layer):\r\n",
        "  def __init__(self, pad,**kwargs):\r\n",
        "        super(ZP, self).__init__(**kwargs)\r\n",
        "        self.zp=ZeroPadding2D(pad)\r\n",
        "  def call(self, x):\r\n",
        "    x = self.zp(x)\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVaRWOmJI0qE"
      },
      "source": [
        "Creating Residual Network 50 and training it on MNIST. I used 100 epochs, 32 batch size for training, 12 batch size for validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Smc6tQU5jRt",
        "outputId": "8cf05d90-1e45-4a4b-c5f1-d3e00141e939"
      },
      "source": [
        "\r\n",
        "model=Sequential(\r\n",
        "      [ZP((3,3),input_shape=(64,64,1)),\r\n",
        "       Conv2D(64,(7,7),strides=(2,2)),\r\n",
        "       BatchNormalization(axis=3),\r\n",
        "       Activation('relu'),\r\n",
        "       MaxPooling2D(2,2),\r\n",
        "       ResidualConv(3,[64,64,256],s=1),\r\n",
        "       Residual(3,[64,64,256]),\r\n",
        "       Residual(3,[64,64,256]),\r\n",
        "       ResidualConv(3,[128,128,512],s=2),\r\n",
        "       Residual(3,[128,128,512]),\r\n",
        "       Residual(3,[128,128,512]),\r\n",
        "       Residual(3,[128,128,512]),\r\n",
        "       ResidualConv(3,[256,256,1024],s=2),\r\n",
        "       Residual(3,[256,256,1024]),\r\n",
        "       Residual(3,[256,256,1024]),\r\n",
        "       Residual(3,[256,256,1024]),\r\n",
        "       Residual(3,[256,256,1024]),\r\n",
        "       Residual(3,[256,256,1024]),\r\n",
        "       ResidualConv(3,[512,512,2048],s=2),\r\n",
        "       Residual(3,[512,512,2048]),\r\n",
        "       Residual(3,[512,512,2048]),\r\n",
        "       AveragePooling2D(2,2),\r\n",
        "       Flatten(),\r\n",
        "       Dense(10,activation='softmax')])\r\n",
        "model.compile(optimizer=Adam(lr=5e-4),loss='sparse_categorical_crossentropy',metrics=['acc'])\r\n",
        "model.summary()\r\n",
        "history = model.fit_generator(train_gen,\r\n",
        "                              steps_per_epoch=len(tX)/BATCHSIZE,\r\n",
        "                              epochs=EPOCHS,\r\n",
        "                              verbose=1,\r\n",
        "                              validation_data=val_gen,\r\n",
        "                              validation_steps=len(valX)/(BATCHSIZE-20))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "model.save_weights('/content/wab.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 84s 42ms/step - loss: 1.6558 - acc: 0.4361 - val_loss: 0.8212 - val_acc: 0.7275\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.6941 - acc: 0.7768 - val_loss: 4.4985 - val_acc: 0.2903\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.5871 - acc: 0.8146 - val_loss: 0.5544 - val_acc: 0.8095\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.4813 - acc: 0.8496 - val_loss: 0.2740 - val_acc: 0.9045\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.3759 - acc: 0.8777 - val_loss: 0.4562 - val_acc: 0.8453\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.3523 - acc: 0.8856 - val_loss: 0.2489 - val_acc: 0.9200\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.3082 - acc: 0.8974 - val_loss: 0.3604 - val_acc: 0.8767\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.3314 - acc: 0.8956 - val_loss: 0.2889 - val_acc: 0.8850\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.2733 - acc: 0.9085 - val_loss: 0.3814 - val_acc: 0.8850\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.2756 - acc: 0.9106 - val_loss: 0.2039 - val_acc: 0.9317\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.2535 - acc: 0.9146 - val_loss: 0.2713 - val_acc: 0.9107\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.2580 - acc: 0.9162 - val_loss: 0.2988 - val_acc: 0.9043\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.2303 - acc: 0.9201 - val_loss: 0.2061 - val_acc: 0.9298\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.2298 - acc: 0.9244 - val_loss: 0.3491 - val_acc: 0.8913\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.2476 - acc: 0.9230 - val_loss: 0.1904 - val_acc: 0.9345\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.2253 - acc: 0.9254 - val_loss: 0.3193 - val_acc: 0.8967\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.2106 - acc: 0.9302 - val_loss: 0.2182 - val_acc: 0.9295\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.2025 - acc: 0.9336 - val_loss: 0.1933 - val_acc: 0.9362\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1966 - acc: 0.9336 - val_loss: 0.2026 - val_acc: 0.9290\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1999 - acc: 0.9330 - val_loss: 0.1808 - val_acc: 0.9342\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.2032 - acc: 0.9331 - val_loss: 0.1538 - val_acc: 0.9467\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1971 - acc: 0.9356 - val_loss: 0.2255 - val_acc: 0.9258\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1845 - acc: 0.9368 - val_loss: 0.1764 - val_acc: 0.9415\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1915 - acc: 0.9362 - val_loss: 0.1691 - val_acc: 0.9423\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1818 - acc: 0.9379 - val_loss: 0.1870 - val_acc: 0.9395\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1748 - acc: 0.9422 - val_loss: 0.1893 - val_acc: 0.9358\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1698 - acc: 0.9430 - val_loss: 0.1826 - val_acc: 0.9365\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 80s 42ms/step - loss: 0.1668 - acc: 0.9436 - val_loss: 0.1792 - val_acc: 0.9392\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1752 - acc: 0.9413 - val_loss: 0.1586 - val_acc: 0.9460\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1660 - acc: 0.9435 - val_loss: 0.1755 - val_acc: 0.9383\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1674 - acc: 0.9433 - val_loss: 0.1446 - val_acc: 0.9528\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 80s 42ms/step - loss: 0.1578 - acc: 0.9470 - val_loss: 0.1466 - val_acc: 0.9510\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1704 - acc: 0.9420 - val_loss: 0.1533 - val_acc: 0.9463\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1623 - acc: 0.9441 - val_loss: 0.1479 - val_acc: 0.9495\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1620 - acc: 0.9443 - val_loss: 0.2171 - val_acc: 0.9283\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1548 - acc: 0.9478 - val_loss: 0.1310 - val_acc: 0.9515\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1514 - acc: 0.9480 - val_loss: 0.1472 - val_acc: 0.9488\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1479 - acc: 0.9482 - val_loss: 0.1478 - val_acc: 0.9505\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1546 - acc: 0.9477 - val_loss: 0.1320 - val_acc: 0.9548\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1435 - acc: 0.9500 - val_loss: 0.1756 - val_acc: 0.9395\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.1453 - acc: 0.9498 - val_loss: 0.1462 - val_acc: 0.9530\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1384 - acc: 0.9528 - val_loss: 0.1515 - val_acc: 0.9482\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1460 - acc: 0.9499 - val_loss: 0.1541 - val_acc: 0.9520\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1787 - acc: 0.9438 - val_loss: 0.1411 - val_acc: 0.9510\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1392 - acc: 0.9515 - val_loss: 0.1327 - val_acc: 0.9550\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1399 - acc: 0.9521 - val_loss: 0.1802 - val_acc: 0.9473\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 80s 42ms/step - loss: 0.1418 - acc: 0.9522 - val_loss: 0.1488 - val_acc: 0.9480\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1389 - acc: 0.9522 - val_loss: 0.1295 - val_acc: 0.9540\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1378 - acc: 0.9526 - val_loss: 0.1644 - val_acc: 0.9420\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1379 - acc: 0.9540 - val_loss: 0.1179 - val_acc: 0.9620\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "zp_7 (ZP)                    (None, 70, 70, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        3200      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "residual_conv_4 (ResidualCon (None, 16, 16, 256)       76928     \n",
            "_________________________________________________________________\n",
            "residual_12 (Residual)       (None, 16, 16, 256)       71552     \n",
            "_________________________________________________________________\n",
            "residual_13 (Residual)       (None, 16, 16, 256)       71552     \n",
            "_________________________________________________________________\n",
            "residual_conv_5 (ResidualCon (None, 8, 8, 512)         383232    \n",
            "_________________________________________________________________\n",
            "residual_14 (Residual)       (None, 8, 8, 512)         282368    \n",
            "_________________________________________________________________\n",
            "residual_15 (Residual)       (None, 8, 8, 512)         282368    \n",
            "_________________________________________________________________\n",
            "residual_16 (Residual)       (None, 8, 8, 512)         282368    \n",
            "_________________________________________________________________\n",
            "residual_conv_6 (ResidualCon (None, 4, 4, 1024)        1520128   \n",
            "_________________________________________________________________\n",
            "residual_17 (Residual)       (None, 4, 4, 1024)        1121792   \n",
            "_________________________________________________________________\n",
            "residual_18 (Residual)       (None, 4, 4, 1024)        1121792   \n",
            "_________________________________________________________________\n",
            "residual_19 (Residual)       (None, 4, 4, 1024)        1121792   \n",
            "_________________________________________________________________\n",
            "residual_20 (Residual)       (None, 4, 4, 1024)        1121792   \n",
            "_________________________________________________________________\n",
            "residual_21 (Residual)       (None, 4, 4, 1024)        1121792   \n",
            "_________________________________________________________________\n",
            "residual_conv_7 (ResidualCon (None, 2, 2, 2048)        6054912   \n",
            "_________________________________________________________________\n",
            "residual_22 (Residual)       (None, 2, 2, 2048)        4471808   \n",
            "_________________________________________________________________\n",
            "residual_23 (Residual)       (None, 2, 2, 2048)        4471808   \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 1, 1, 2048)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,601,930\n",
            "Trainable params: 23,548,810\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpq7xvr9M2d5"
      },
      "source": [
        "Plot some graphs of loss and acc\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijkq9hglKi7P"
      },
      "source": [
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title(\"Model loss on training and val sets\")\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title(\"Model acc on training and val sets\")\r\n",
        "plt.ylabel('acc')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5q1O7nuKGq0"
      },
      "source": [
        "Now get results of Test sets loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ3m6VTcWLm_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "a1340c4c-a1ab-405a-84d9-e57ff457bd6a"
      },
      "source": [
        "test_loss,test_acc = model.evaluate(teX,teY,batch_size=(BATCHSIZE-10))\r\n",
        "print(f\"Test loss: {test_loss}\\nTest acc: {test_acc*100}%\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-88c1f3ff5fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/wab.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}
